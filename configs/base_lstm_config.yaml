model: 'LSTM'

embed_size: 25

hidden_size: 150

num_layers: 1

epochs: 10

patience: 3

seq_len: 16

learning_rate: 0.002

log_interval: 5

batch_size: 256

save_path: "models"
